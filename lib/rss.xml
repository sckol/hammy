<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[hammy]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib/media/favicon.png</url><title>hammy</title><link></link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Mon, 24 Feb 2025 04:37:18 GMT</lastBuildDate><atom:link href="lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Mon, 24 Feb 2025 04:37:17 GMT</pubDate><ttl>60</ttl><dc:creator></dc:creator><item><title><![CDATA[Overview]]></title><description><![CDATA[ 
 <br><br>Consider a one-dimensional random walk, where at each step the particle moves either in the positive or negative direction from a fixed starting point. The length of the walk is fixed and equal to T. Choose only those walks where the final position of the particle is on the set TARGETS, e.g. walks ending at 0, 1 or 5 from the starting point in positive direction. For each element in this set we compute a statistics. In this experiment the statistics we collect is the distribution of the particle's positions at intermediate steps between the start and the end of the walk, for example after 100, 200, 300, ... steps. This set is called CHECKPOINTS.<br>Then we transform this statistic into a single value that is defined for each step. This value defines the trajectory of the particle. Different end positions define different trajectories because we have considered the statistics for them separately. <br>The function that transforms the statistics into a trajectory is what we call a trajectory function. An example of a trajectory function is the empirical mode (the most frequent value of the statistics). In this case the domain of the function is the nodes of the graph where the walk takes place, i. e. one dimensional discrete lattice.<br>The desirable property of the trajectory function is that it is independent of the labelling of the graph nodes. In this experiment, there is a natural way to label the graph nodes by their distance and direction from the starting point. We can calculate the mean and variance of the particle positions. But for a general graph there is no such labelling and we need to choose a trajectory function that does not rely on it. The empirical mode is such a function, but unfortunately it is not well defined for each checkpoint.<br>For example, consider a random walk of length 1000 with target 9 at checkpoint 500. Collision of empirical modes is possible when there is an equal number of walks at position 4 and 5. So we must either consider the trajectory function to be multivalued or define an algorithm to resolve such collisions. Furthermore, such collisions are not easy to detect. In practice, if we have a fixed number of simulations with a high probability, we will have a single empirical mode randomly chosen between 4 and 5.<br>]]></description><link>experiments/1_walk.html</link><guid isPermaLink="false">experiments/1_walk.md</guid><pubDate>Mon, 24 Feb 2025 04:36:57 GMT</pubDate></item><item><title><![CDATA[hammy: Main page]]></title><description><![CDATA[ 
 <br><br><br>Consider a graph where we perform a random walk with a fixed number of steps from a starting node S. We keep only those walks that end at a particular point E. We can then define a “trajectory” by identifying the most frequently visited node at each intermediate step. The aim of this project is to show that such a trajectory exhibits “physical” behavior. For example, on an infinite 1D/2D/3D lattice graph, the trajectory would correspond to a discrete version of uniform motion between S and E. We can introduce “potential energy” by terminating the random walk at each step with a probability based on the potential energy of the particle's location. In this scenario, the trajectory would show the particle slowing down in areas of high potential energy and accelerating in areas of low potential energy.<br>The hammy project aims to demonstrate these concepts and explore the correspondence between physical notions and statistics of random walks, including:<br>
<br>Lagrangian,
<br>continuous position on a discrete graph,
<br>momentum and energy,
<br>Hamiltonian function.
<br><br>hammy consists of a series of experiments, each running simulations of random walks, calculating their statistics, and interpreting them in physical terms. These experiments are conducted in Jupyter Notebooks. Some experiments require substantial computational resources (memory, CPUs, and GPUs), so utilities were developed to facilitate running experiments in a cloud environment efficiently and cost-effectively.<br>Code for experiments and utilities is <a data-tooltip-position="top" aria-label="https://github.com/sckol/hammy" rel="noopener nofollow" class="external-link" href="https://github.com/sckol/hammy" target="_blank">available on GitHub</a>.<br><br>Random walk simulations are prone to bugs, some of which are difficult to detect. To ensure reliability, the simulations are implemented in both Python and C. During development, it's more convenient to use CPUs to run the code. However, as experiments often require many iterations to achieve more accurate results, GPUs are used for final runs. For Python code, the <a data-tooltip-position="top" aria-label="https://cupy.dev/" rel="noopener nofollow" class="external-link" href="https://cupy.dev/" target="_blank">CuPy</a> library allows to write code that runs that runs on both CPUs and GPUs. For the C implementation, a simple framework of macros and code-writing rules has been developed, allowing the use of a single source for both CPU and GPU execution.<br>We keep separate datasets of simulation results for:<br>
<br>Python implementations on CPU and GPU,
<br>C implementation on CPU,
<br>C implementation on GPU,
<br>aggregated data across all implementations.
<br>Hypotheses are tested on the different datasets to identify any discrepancies (which may indicate bugs) and finally on the aggregated data.<br><br>The docker folder contains files for running experiments in Yandex Cloud using <a data-tooltip-position="top" aria-label="https://yandex.cloud/en/docs/cos/" rel="noopener nofollow" class="external-link" href="https://yandex.cloud/en/docs/cos/" target="_blank">Container Solution</a>. The `hammy-base.Dockerfile' is an image with the following features<br>
<br>Python is installed with CuPy
<br>Yandex Cloud Monitoring is enabled, which allows you to monitor CPU and memory usage in real time.
<br>the logs of the main script (which must be named as main.sh in the descendant images) are redirected to Yandex Cloud Logging using the log_yc bash function
<br>The main script is executed in a wrapper hammy_entrypoint.sh, which at the end of the main script's execution either deletes the machine (default) or shuts it down (do-nothing option is also available).
<br>A run_nice bash function is available which sets a lower priority for the main script, to ensure that the monitoring and wrapper processes continue to work even if the main script exhausts memory or CPU.
<br>An example of a hammy-base descendant image is in chquery.Dockerfile. It runs a Clickhouse instance connected to Yandex Cloud Storage as an S3 bucker, and passes a query from the container's CMD argument (allowing different queries to be run using the same image). Clickhouse can take the data from the S3 bucker and return query results to it. This allows Clickhouse to be used as part of a data processing pipeline. The script create_query_machine.sh runs a virtual machine in Yandex Cloud with this image and passes the content of the given file as CMD argument.<br>Sometimes when writing queries you may want to use variable substitution or cycles (for example, if you have a table with many columns position_1, position_2, ...). The process_jinja.py script allows you to write queries as <a data-tooltip-position="top" aria-label="https://jinja.palletsprojects.com/" rel="noopener nofollow" class="external-link" href="https://jinja.palletsprojects.com/" target="_blank">Jinja</a> templates and the script will convert them into regular SQL files.<br>The create_hammy_machine.sh starts a virtual machine with GPU support from a Docker image for the given experiment name.<br><br>]]></description><link>readme.html</link><guid isPermaLink="false">README.md</guid><pubDate>Mon, 24 Feb 2025 04:36:57 GMT</pubDate></item></channel></rss>